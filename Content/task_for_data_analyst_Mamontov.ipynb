{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fe179e7-68e0-4095-9304-4e6ba00f7d91",
   "metadata": {},
   "source": [
    "## Client Requirements\n",
    "1. **Search Repositories**: Find repositories related to \"machine learning\" with at least 100 stars and written in Python.\n",
    "2. **Fetch Commits**: Retrieve the latest 10 commits from the top repository found.\n",
    "3. **Extract Repository Contents**: Inspect the contents of the top-level directory of the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a33d544d-4650-4626-bc13-5469a1e53daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "677b621e-f4d7-41f0-9e03-39a323bef8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "GITHUB_TOKEN = \"\"\n",
    "\n",
    "BASE_URL = \"https://api.github.com\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {GITHUB_TOKEN}\",\n",
    "    \"Accept\": \"application/vnd.github+json\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db3933e0-1795-4af7-83e1-5b6ca8b41299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_repositories(query, per_page=10):\n",
    "    \"\"\"\n",
    "    Searches for repositories based on a query.\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL}/search/repositories\"\n",
    "    params = {\"q\": query, \"per_page\": per_page}\n",
    "    response = requests.get(url, headers=HEADERS, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"items\"]\n",
    "    else:\n",
    "        print(f\"Error {response.status_code}: {response.json()['message']}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0426192-5afe-4d41-bbb0-f5996313a087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commits(owner, repo, per_page=10):\n",
    "    \"\"\"\n",
    "    Fetches the latest commits for a given repository.\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL}/repos/{owner}/{repo}/commits\"\n",
    "    params = {\"per_page\": per_page}\n",
    "    response = requests.get(url, headers=HEADERS, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error {response.status_code}: {response.json()['message']}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00406ecf-1329-4faf-a976-9bfb3ab4d7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contents(owner, repo, path=\"\"):\n",
    "    \"\"\"\n",
    "    Fetches the contents of a repository.\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL}/repos/{owner}/{repo}/contents/{path}\"\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error {response.status_code}: {response.json()['message']}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acad200d-5fb4-435a-b7cf-b36bd1c118b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository: josephmisiti/awesome-machine-learning, Stars: 66168\n",
      "Repository: wepe/MachineLearning, Stars: 5256\n",
      "Repository: Jack-Cherish/Machine-Learning, Stars: 9202\n",
      "Repository: lawlite19/MachineLearning_Python, Stars: 7326\n",
      "Repository: lazyprogrammer/machine_learning_examples, Stars: 8403\n"
     ]
    }
   ],
   "source": [
    "query = \"machine learning language:Python\"\n",
    "repositories = search_repositories(query, per_page=5)\n",
    "\n",
    "if repositories:\n",
    "    for repo in repositories:\n",
    "        print(f\"Repository: {repo['full_name']}, Stars: {repo['stargazers_count']}\")\n",
    "else:\n",
    "    print(\"No repositories found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6223b98b-ffb9-4657-95b3-33684eeca8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recent Commits:\n",
      "SHA: a9cfd245f6acb6a03407c370b8d520999285afa1, Message: Merge pull request #1001 from debashishc/master\n",
      "\n",
      "docs(readme): added EspNet tool for speech processing tasks in Python\n",
      "SHA: 3e760ed5c057280cb0b0a044dda9be44fc3618f1, Message: Merge pull request #1000 from anmorgan24/add-opik\n",
      "\n",
      "Add Opik\n",
      "SHA: 5f7293e5c249e217947a55ab5b1bc95d250678e1, Message: docs(readme): made EspNet description more concise\n",
      "SHA: d5de41ccbec7725f69c2e54c8d18a1e564aab223, Message: docs(readme): add EspNet for Speech Processing Tasks\n",
      "SHA: 50ecf61e10e2a368ccf153657226251952b1bded, Message: Add Opik\n",
      "\n",
      "Comet recently sunset CometLLM and in its place launched Opik, a tool with most of the same capabilities as the old CometLLM but with a whole host of additional features and capabilities. This PR updates the readme accordingly.\n",
      "\n",
      "Signed-off-by: Abby Morgan abigailm@comet.com\n"
     ]
    }
   ],
   "source": [
    "if repositories:\n",
    "    owner = repositories[0][\"owner\"][\"login\"]\n",
    "    repo_name = repositories[0][\"name\"]\n",
    "\n",
    "    commits = get_commits(owner, repo_name, per_page=5)\n",
    "    print(\"\\nRecent Commits:\")\n",
    "    for commit in commits:\n",
    "        print(f\"SHA: {commit['sha']}, Message: {commit['commit']['message']}\")\n",
    "else:\n",
    "    print(\"No repositories to fetch commits from.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c27f184d-519c-45c9-8060-0aa6107dca2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Repository Contents:\n",
      "Type: file, Name: LICENSE\n",
      "Type: file, Name: README.md\n",
      "Type: file, Name: blogs.md\n",
      "Type: file, Name: books.md\n",
      "Type: file, Name: courses.md\n",
      "Type: file, Name: events.md\n",
      "Type: file, Name: meetups.md\n",
      "Type: file, Name: ml-curriculum.md\n",
      "Type: dir, Name: scripts\n"
     ]
    }
   ],
   "source": [
    "if repositories:\n",
    "    contents = get_contents(owner, repo_name)\n",
    "    print(\"\\nRepository Contents:\")\n",
    "    for item in contents:\n",
    "        print(f\"Type: {item['type']}, Name: {item['name']}\")\n",
    "else:\n",
    "    print(\"No repositories to fetch contents from.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89c41329-6935-43fa-b29c-5c24a68c49a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_rate_limit():\n",
    "    \"\"\"\n",
    "    Checks the GitHub API rate limit.\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL}/rate_limit\"\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        rate_limit = response.json()[\"rate\"]\n",
    "        print(f\"Remaining requests: {rate_limit['remaining']}\")\n",
    "        return rate_limit\n",
    "    else:\n",
    "        print(f\"Error {response.status_code}: {response.json()['message']}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90c62d67-b81a-47c4-9fbe-1b151545e002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining requests: 4974\n"
     ]
    }
   ],
   "source": [
    "rate_limit = check_rate_limit()\n",
    "if rate_limit and rate_limit[\"remaining\"] == 0:\n",
    "    wait_time = rate_limit[\"reset\"] - int(time.time())\n",
    "    print(f\"Rate limit exceeded. Waiting for {wait_time} seconds.\")\n",
    "    time.sleep(wait_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "947ee423-2908-4d04-9784-54f7fcafbf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to repositories.json\n",
      "Data saved to commits.json\n"
     ]
    }
   ],
   "source": [
    "def save_to_file(data, filename):\n",
    "    \"\"\"\n",
    "    Saves data to a JSON file.\n",
    "    \"\"\"\n",
    "    with open(filename, \"w\") as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "save_to_file(repositories, \"../results/repositories.json\")\n",
    "\n",
    "save_to_file(commits, \"../results/commits.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922413e3-d289-4bc3-8a55-38196c483d09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
